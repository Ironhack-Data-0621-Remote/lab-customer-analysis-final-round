{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Final Round\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we still keep using the marketing_customer_analysis.csv file that you can find in the files_for_lab folder.\n",
    "\n",
    "It's time to put it all together. Remember the previous rounds and follow the steps as shown in previous lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Problem (case study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Description.\n",
    "\n",
    "- Goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from a customer analysis of a car ensurance company.\n",
    "# Based on the given data the objective is to create a prediction model to find out if the \n",
    "# Total claim amount can be predicted by other information avalible about the cosumer and how valid this prediction is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from scipy.special import inv_boxcox\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "data = pd.read_csv('files_for_lab/csv_files/marketing_customer_analysis.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Cleaning/Wrangling/EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change headers names.\n",
    "- Deal with NaN values.\n",
    "- Categorical Features.\n",
    "- Numerical Features.\n",
    "- Exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfheaders(df):\n",
    "    df.rename(columns={'Customer':'id', 'EmploymentStatus':'employment_status'}, inplace=True)\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "# using the 2 operations together only works when removing the 'df=' infront of the first satemment. Why?\n",
    "# the first operation doesnt work at all in a function without the inplace parameter. Outside of a function it does work. Why?\n",
    "\n",
    "clean_dfheaders(data)\n",
    "\n",
    "data.duplicated(subset=['id']).unique()\n",
    "# or data['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates with drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('id', inplace=True)\n",
    "\n",
    "data['effective_to_date'] = pd.to_datetime(data['effective_to_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = list(data.select_dtypes(include=[np.number]).columns.values)\n",
    "cat_col = list(data.select_dtypes(include=[np.object]).columns.values)\n",
    "\n",
    "for col in cat_col:\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# cleaning columns examples\n",
    "\n",
    "data['customer_lifetime_value'] = data['customer_lifetime_value'].apply(lambda x: float(str(x).replace('%', '')))\n",
    "\n",
    "def clean_gender(x):\n",
    "    if str(x).lower().startswith('m'):\n",
    "        return 'M'\n",
    "    elif str(x).lower().startswith('f'):\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'O'\n",
    "\n",
    "data['gender'] = data['gender'].apply(clean_gender)\n",
    "\n",
    "data['state'] = data['state'].apply(lambda x: 'California' if str(x).lower().startswith('cal')\n",
    "                                                 else 'Nevada' if x == 'NV'\n",
    "                                                 else 'Arizona' if x == 'AZ'\n",
    "                                                 else x)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# replacing NaN values \n",
    "\n",
    "def clean_df(df):\n",
    "    replace_dict = {\n",
    "        'id': '',\n",
    "        'state': 'California',\n",
    "        'customer_lifetime_value': '',\n",
    "        'response': 'No',\n",
    "        'coverage': '',\n",
    "        'education': '',\n",
    "        'effective_to_date': '',\n",
    "        'employment_status': '',\n",
    "        'gender': '',\n",
    "        'income': '',\n",
    "        'location_code': '',\n",
    "        'marital_status': '',\n",
    "        'monthly_premium_auto': '',\n",
    "        'months_since_last_claim': df['months_since_last_claim'].median(),\n",
    "        'months_since_policy_inception': '',\n",
    "        'number_of_open_complaints': df['number_of_open_complaints'].median(),\n",
    "        'number_of_policies': '',\n",
    "        'policy_type': '',\n",
    "        'policy': '',\n",
    "        'renew_offer_type': '',\n",
    "        'sales_channel': '',\n",
    "        'total_claim_amount': '',\n",
    "        'vehicle_class': 'Four-Door Car',\n",
    "        'vehicle_size': 'Medsize',\n",
    "        'vehicle_type': 'A',  \n",
    "    }\n",
    "    \n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].fillna(replace_dict[column])\n",
    "        \n",
    "# replacing the value with a mode() expression, e.g. 'state': data['state'].mode() doesnt'work. why?\n",
    "# replacing NaN on categorical columns with mode or value generateted by random, set up in a way that the ratio of unique values stays the same\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(data.corr())\n",
    "\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(data.corr(), mask=mask, annot=True)\n",
    "plt.show()\n",
    "\n",
    "# remove multicolinearity > 0.9 \n",
    "# > 0.75 check again with model metrics\n",
    "# when removing columns, keep the ones that have the highest correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling before any data changes to compare againt modeling after changes\n",
    "# possible feature selection based on P values < 0.05\n",
    "\n",
    "data_num = data.select_dtypes(include=[np.number])\n",
    "\n",
    "ols1_x = data_num.drop(['total_claim_amount'], axis=1)\n",
    "ols1_y = data['total_claim_amount']\n",
    "ols1_x = sm.add_constant(ols1_x)\n",
    "\n",
    "ols1_model = sm.OLS(ols1_y,ols1_x).fit()\n",
    "print(ols1_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1_x = data_num.drop(['total_claim_amount'], axis=1)\n",
    "lm1_y = data['total_claim_amount'] \n",
    "\n",
    "lm1 = LinearRegression()\n",
    "lm1_model = lm1.fit(lm1_x,lm1_y)\n",
    "\n",
    "lm1_predictions = lm1.predict(lm1_x)\n",
    "lm1_r2 = round(r2_score(lm1_y, lm1_predictions),2)\n",
    "lm1_rmse = mean_squared_error(lm1_y, lm1_predictions, squared=False)\n",
    "lm1_mse = mean_squared_error(lm1_y, lm1_predictions, squared=True)\n",
    "lm1_mae = mean_absolute_error(lm1_y, lm1_predictions)\n",
    "\n",
    "print(\"R2:\", lm1_r2)\n",
    "print(\"RMSE:\", lm1_rmse)\n",
    "print(\"MSE:\", lm1_mse)\n",
    "print(\"MAE:\", lm1_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    sns.distplot(data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_col:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dealing with outliers.\n",
    "- Normalization.\n",
    "- Encoding Categorical Data.\n",
    "- Splitting into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for values <= 0 and replacing them before tranforming\n",
    "for col in num_col:\n",
    "    neg_val = len(data[data[col] < 0])\n",
    "    zero_val = len(data[data[col] == 0])\n",
    "     \n",
    "    if neg_val > 0:\n",
    "        print('Negative values in', col, ':', neg_val)\n",
    "    elif zero_val > 0:\n",
    "        print('Zeros in', col, ':', zero_val)\n",
    "    else:\n",
    "        print('Column', col, 'is ok.')\n",
    "        \n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for replacing values <= 0\n",
    "\n",
    "def positive_values(df, in_columns=df.select_dtypes(np.number).columns, skip_columns=[]):\n",
    "    for col in in_columns:\n",
    "        if col not in skip_columns:\n",
    "            df[col] = np.where(df[col] <= 0, df[col].median(), df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion for trasformation\n",
    "\n",
    "def boxcox_transform(df, in_columns=df.select_dtypes(np.number).columns, skip_columns=[]):\n",
    "    _ci = {column: None for column in in_columns}\n",
    "    for column in in_columns:\n",
    "        if column not in skip_columns:\n",
    "            df[column] = np.where(df[column]<=0, np.NAN, df[column]) \n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "            transformed_data, ci = stats.boxcox(df[column])\n",
    "            df[column] = transformed_data\n",
    "            _ci[column] = [ci] \n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.distplot(df[column])\n",
    "            plt.show()\n",
    "    return df, _ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace/remove outliers\n",
    "# you can decide to remove outliers after log / boxcox transformation\n",
    "# since these might take care of some outliers for you.\n",
    "\n",
    "def replace_outliers(df, threshold=1.5, in_columns=df.select_dtypes(np.number).columns, skip_columns=[], median_repl=[]):\n",
    "    for column in in_columns:\n",
    "        if column not in skip_columns:\n",
    "            upper = np.percentile(df[column],75)\n",
    "            lower = np.percentile(df[column],25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + (threshold * iqr)\n",
    "            lower_limit = lower - (threshold * iqr)\n",
    "            \n",
    "            if column not in median_repl:\n",
    "                df.loc[df[column] > upper_limit, column] = upper_limit\n",
    "                df.loc[df[column] < lower_limit, column] = lower_limit\n",
    "            else:\n",
    "                df.loc[df[column] > upper_limit, column] = df[column].median()\n",
    "                df.loc[df[column] < lower_limit, column] = df[column].median()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# or remove outliers\n",
    "# make sure you are droping the outliers only after the feature selection,\n",
    "# just so you don't end up losing rows because of outliers in a column you won't use\n",
    "\n",
    "def remove_outliers(df, threshold=1.5, in_columns=df.select_dtypes(np.number).columns, skip_columns=[]):\n",
    "    for column in in_columns:\n",
    "        if column not in skip_columns:\n",
    "            upper = np.percentile(df[column],75)\n",
    "            lower = np.percentile(df[column],25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + (threshold * iqr)\n",
    "            lower_limit = lower - (threshold * iqr)\n",
    "            df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = positive_values(data_t, in_columns=['income', 'months_since_last_claim', 'customer_lifetime_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t, _ci = boxcox_transform(data_t, skip_columns=['monthly_premium_auto'])\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = replace_outliers(data_t, threshold=1.5, in_columns=['customer_lifetime_value', 'monthly_premium_auto', 'number_of_policies'], \n",
    "                          median_repl=['customer_lifetime_value', 'monthly_premium_auto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-y split\n",
    "t_num = list(data_t.select_dtypes(include=[np.number]).columns.values)\n",
    "t_object = list(data_t.select_dtypes(include=[np.object]).columns.values)\n",
    "\n",
    "t_drop = t_object + [t_num[7]] + ['effective_to_date']\n",
    "x_t = data_t.drop(t_drop, axis=1)\n",
    "y = data_t['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and Standardize\n",
    "to_normal = Normalizer().fit(x_t)\n",
    "x_normalized = to_normal.transform(x_t)\n",
    "data_sn = pd.DataFrame(x_normalized)\n",
    "\n",
    "# to_standard = StandardScaler().fit(data_sn)\n",
    "# x_standardized = to_standard.transform(data_sn)\n",
    "# data_sn = pd.DataFrame(x_standardized)\n",
    "\n",
    "sn_col = ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'months_since_last_claim', 'months_since_policy_inception', 'number_of_open_complaints', 'number_of_policies']\n",
    "\n",
    "for idx, col in enumerate(sn_col):\n",
    "    data_sn.rename(columns={idx:col}, inplace=True)\n",
    "\n",
    "data_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = data_t.select_dtypes(include = [np.object])\n",
    "\n",
    "for col in t_object:\n",
    "    print(x_cat[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "x_1h = x_cat.drop(['coverage', 'education', 'vehicle_size'], axis=1)\n",
    "data_1h = pd.get_dummies(x_1h, drop_first=True)\n",
    "\n",
    "x_label1 = x_cat['coverage']\n",
    "x_label2 = x_cat['education']\n",
    "x_label3 = x_cat['vehicle_size']\n",
    "\n",
    "le1 = LabelEncoder().fit(x_label1).transform(x_label1)\n",
    "le2 = LabelEncoder().fit(x_label2).transform(x_label2)\n",
    "le3 = LabelEncoder().fit(x_label3).transform(x_label3)\n",
    "\n",
    "data_le1 = pd.DataFrame(le1)\n",
    "data_le1.columns = ['coverage']\n",
    "data_le2 = pd.DataFrame(le2)\n",
    "data_le2.columns = ['education']\n",
    "data_le3 = pd.DataFrame(le3)\n",
    "data_le3.columns = ['vehicle_size']\n",
    "target = data_t[['total_claim_amount','vehicle_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([data_sn, data_1h, data_le1, data_le2, data_le3, target], axis=1)\n",
    "\n",
    "data_x = pd.DataFrame(x)\n",
    "\n",
    "columns_sn = list(data_sn.columns.values)\n",
    "columns_1h = list(data_1h.columns.values)\n",
    "columns_le1 = list(data_le1.columns.values)\n",
    "columns_le2 = list(data_le2.columns.values)\n",
    "columns_le3 = list(data_le3.columns.values)\n",
    "target_col = list(target.columns.values)\n",
    "columns_x = columns_sn + columns_1h + columns_le1 + columns_le2 + columns_le3 + target_col\n",
    "data_x.columns = columns_x\n",
    "\n",
    "data_x = data_x.drop(['vehicle_class'], axis=1)\n",
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-splits for models woutout and with encoded cathegorical columns\n",
    "# use data_sn insted of data_t for normalized/standardized data\n",
    "\n",
    "lm2_x = data_t.drop(['total_claim_amount'], axis=1)\n",
    "lm2_x_full = data_x.drop(['total_claim_amount'], axis=1)\n",
    "lm2_y = data_t['total_claim_amount']\n",
    "\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(lm2_x,lm2_y, test_size=0.2, random_state=7)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(lm2_x_full,lm2_y, test_size=0.2, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = LinearRegression()\n",
    "lm2.fit(x1_train, y1_train)\n",
    "\n",
    "lm2_predictions_1 = lm2.predict(x1_test)\n",
    "lm2_predictions_2 = lm2.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R2.\n",
    "- MSE.\n",
    "- RMSE.\n",
    "- MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2_r2_1 = round(r2_score(y1_test, lm2_predictions_1),2)\n",
    "lm2_r2_2 = round(r2_score(y2_test, lm2_predictions_2),2)\n",
    "\n",
    "print(\"Model 1 R2:\", lm2_r2_1)\n",
    "print(\"Model 2 R2:\", lm2_r2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = inv_boxcox(predictions_1, _ci['total_claim_amount'])\n",
    "predictions_2 = inv_boxcox(predictions_2, _ci['total_claim_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2_r2_1 = round(r2_score(y1_test, lm2_predictions_1),2)\n",
    "lm2_rmse_1 = mean_squared_error(y1_test, lm2_predictions_1, squared=False)\n",
    "lm2_mse_1 = mean_squared_error(y1_test, lm2_predictions_1, squared=True)\n",
    "lm2_mae_1 = mean_absolute_error(y1_test, lm2_predictions_1)\n",
    "\n",
    "lm2_r2_2 = round(r2_score(y2_test, lm2_predictions_2),2)\n",
    "lm2_rmse_2 = mean_squared_error(y2_test, lm2_predictions_2, squared=False)\n",
    "lm2_mse_2 = mean_squared_error(y2_test, lm2_predictions_2, squared=True)\n",
    "lm2_mae_2 = mean_absolute_error(y2_test, lm2_predictions_2)\n",
    "\n",
    "print(\"Model 1 R2:\", lm2_r2_1)\n",
    "print(\"Model 1 RMSE:\", lm2_rmse_1)\n",
    "print(\"Model 1 MSE:\", lm2_mse_1)\n",
    "print(\"Model 1 MAE:\", lm2_mae_1)\n",
    "\n",
    "print(\"Model 2 R2:\", lm2_r2_2)\n",
    "print(\"Model 2 RMSE:\", lm2_rmse_2)\n",
    "print(\"Model 2 MSE:\", lm2_mse_2)\n",
    "print(\"Model 2 MAE:\", lm2_mae_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 - Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = pd.DataFrame()\n",
    "results_1['true'] = inv_boxcox(y1_test, _ci['total_claim_amount'])\n",
    "results_1['predicted'] = predictions_1\n",
    "results_1['residual'] = results_1.apply(lambda x: abs(x['true'] - x['predicted']), axis=1)\n",
    "\n",
    "results_2 = pd.DataFrame()\n",
    "results_2['true'] = inv_boxcox(y2_test, _ci['total_claim_amount'])\n",
    "results_2['predicted'] = predictions_2\n",
    "results_2['residual'] = results_2.apply(lambda x: abs(x['true'] - x['predicted']), axis=1)\n",
    "\n",
    "results_1\n",
    "#results_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3Brew",
   "language": "python",
   "name": "python3brew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
